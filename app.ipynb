{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for Landmark Classification\n",
    "\n",
    "### A simple app\n",
    "\n",
    "In this notebook we build a very simple app that uses our exported model.\n",
    "\n",
    "> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n",
    "\n",
    "### Test your app\n",
    "Go to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n",
    "\n",
    "The app will show the top 5 classes that the model think are most relevant for the picture you have uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /root/.local/lib/python3.7/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /root/.local/lib/python3.7/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.13.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (45.2.0.post20200209)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.6.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 887.5 MB 6.8 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 52.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1 MB 7.3 kB/s  eta 0:00:01██████████████████████▍       | 425.0 MB 77.8 MB/s eta 0:00:02█████████     | 469.5 MB 66.8 MB/s eta 0:00:02ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0 MB 61.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1 MB 27 kB/s  eta 0:00:01███▍                 | 142.4 MB 2.5 MB/s eta 0:01:10███████              | 177.8 MB 2.9 MB/s eta 0:00:49   | 194.0 MB 2.9 MB/s eta 0:00:43�█████████           | 207.4 MB 2.6 MB/s eta 0:00:43█████▋        | 233.9 MB 2.6 MB/s eta 0:00:33 | 259.7 MB 2.6 MB/s eta 0:00:23��█████████    | 277.5 MB 2.6 MB/s eta 0:00:16██████████████████████████████  | 297.5 MB 3.1 MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\"\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[K     |████████████████████████████████| 849 kB 63.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.2)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch) (45.2.0.post20200209)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.0.4)\n",
      "\u001b[31mERROR: torchtext 0.12.0 has requirement torch==1.11.0, but you'll have torch 1.13.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, torch, torchvision\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting typing_extensions\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "\u001b[31mERROR: torchtext 0.12.0 has requirement torch==1.11.0, but you'll have torch 1.13.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions\n",
      "Successfully installed typing-extensions-4.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing_extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nUnknown builtin op: torchvision::_interpolate_bilinear2d_aa.\nCould not find any similar ops to torchvision::_interpolate_bilinear2d_aa. This op may not exist or may not be currently supported in TorchScript.\n:\n  File \"code/__torch__/torchvision/transforms/functional_tensor.py\", line 112\n      _35 = torch.eq(interpolation0, \"bilinear\")\n      if _35:\n        img3 = ops.torchvision._interpolate_bilinear2d_aa(img0, [new_h, new_w], False)\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        img2 = img3\n      else:\n'resize' is being compiled since it was called from 'resize'\nSerialized   File \"code/__torch__/torchvision/transforms/functional.py\", line 13\n    max_size: Optional[int]=None,\n    antialias: Optional[bool]=None) -> Tensor:\n  _0 = __torch__.torchvision.transforms.functional_tensor.resize\n  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n  interpolation0 = unchecked_cast(__torch__.torchvision.transforms.functional.InterpolationMode, interpolation)\n  interpolation1 = unchecked_cast(__torch__.torchvision.transforms.functional.InterpolationMode, interpolation0)\n'resize' is being compiled since it was called from 'Resize.forward'\nSerialized   File \"code/__torch__/torchvision/transforms/transforms.py\", line 12\n  def forward(self: __torch__.torchvision.transforms.transforms.Resize,\n    img: Tensor) -> Tensor:\n    _0 = __torch__.torchvision.transforms.functional.resize\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    size = self.size\n    interpolation = self.interpolation\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-823669a4615f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Decide which model you want to use among the ones exported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlearn_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoints/transfer_exported.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mon_click_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/jit/_serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, _extra_files)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompilationUnit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mcpp_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_ir_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_extra_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         cpp_module = torch._C.import_ir_module_from_buffer(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nUnknown builtin op: torchvision::_interpolate_bilinear2d_aa.\nCould not find any similar ops to torchvision::_interpolate_bilinear2d_aa. This op may not exist or may not be currently supported in TorchScript.\n:\n  File \"code/__torch__/torchvision/transforms/functional_tensor.py\", line 112\n      _35 = torch.eq(interpolation0, \"bilinear\")\n      if _35:\n        img3 = ops.torchvision._interpolate_bilinear2d_aa(img0, [new_h, new_w], False)\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        img2 = img3\n      else:\n'resize' is being compiled since it was called from 'resize'\nSerialized   File \"code/__torch__/torchvision/transforms/functional.py\", line 13\n    max_size: Optional[int]=None,\n    antialias: Optional[bool]=None) -> Tensor:\n  _0 = __torch__.torchvision.transforms.functional_tensor.resize\n  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n  interpolation0 = unchecked_cast(__torch__.torchvision.transforms.functional.InterpolationMode, interpolation)\n  interpolation1 = unchecked_cast(__torch__.torchvision.transforms.functional.InterpolationMode, interpolation0)\n'resize' is being compiled since it was called from 'Resize.forward'\nSerialized   File \"code/__torch__/torchvision/transforms/transforms.py\", line 12\n  def forward(self: __torch__.torchvision.transforms.transforms.Resize,\n    img: Tensor) -> Tensor:\n    _0 = __torch__.torchvision.transforms.functional.resize\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    size = self.size\n    interpolation = self.interpolation\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import VBox, Button, FileUpload, Output, Label\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "# Decide which model you want to use among the ones exported\n",
    "learn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\")\n",
    "\n",
    "def on_click_classify(change):\n",
    "\n",
    "    # Load image that has been uploaded\n",
    "    fn = io.BytesIO(btn_upload.value[0]['content'])\n",
    "\n",
    "    img = Image.open(fn)\n",
    "    img.load()\n",
    "\n",
    "    # Let's clear the previous output (if any)\n",
    "    out_pl.clear_output()\n",
    "\n",
    "    # Display the image\n",
    "    with out_pl:\n",
    "\n",
    "        ratio = img.size[0] / img.size[1]\n",
    "        c = img.copy()\n",
    "        c.thumbnail([ratio * 200, 200])\n",
    "        display(c)\n",
    "\n",
    "    # Transform to tensor\n",
    "    timg = T.ToTensor()(img).unsqueeze_(0)\n",
    "\n",
    "    # Calling the model\n",
    "    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Get the indexes of the classes ordered by softmax\n",
    "    # (larger first)\n",
    "    idxs = np.argsort(softmax)[::-1]\n",
    "    \n",
    "    # Loop over the classes with the largest softmax\n",
    "    for i in range(5):\n",
    "        # Get softmax value\n",
    "        p = softmax[idxs[i]]\n",
    "    \n",
    "        # Get class name\n",
    "        landmark_name = learn_inf.class_names[idxs[i]]\n",
    "        \n",
    "        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n",
    "\n",
    "\n",
    "# Putting back btn_upload to a widget for next cell\n",
    "btn_upload = FileUpload()\n",
    "\n",
    "btn_run = Button(description=\"Classify\")\n",
    "btn_run.on_click(on_click_classify)\n",
    "\n",
    "labels = []\n",
    "for _ in range(5):\n",
    "    labels.append(Label())\n",
    "\n",
    "out_pl = Output()\n",
    "out_pl.clear_output()\n",
    "\n",
    "wgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\n",
    "wgs.extend(labels)\n",
    "\n",
    "VBox(wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Standalone app or web app\n",
    "\n",
    "You can run this notebook as a standalone app on your computer by following these steps:\n",
    "\n",
    "1. Download this notebook in a directory on your machine\n",
    "2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n",
    "3. Install voila if you don't have it already (``pip install voila``)\n",
    "4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n",
    "5. Customize your notebook to make your app prettier and rerun voila\n",
    "\n",
    "You can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your submission archive\n",
    "\n",
    "Now that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/create_submit_pkg.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
